{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR87N1pd0sNt"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.feature_extraction.text as sk_text\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "# Set the desired TensorFlow output level for this example\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G26NAOGT9UrS"
      },
      "outputs": [],
      "source": [
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column. \n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7XQVbPRC_qw",
        "outputId": "0dd152a6-97e4-4897-d284-75ea002be91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'path = \"/content/drive/MyDrive/yelp_dataset/\"\\n    \\nfilename = os.path.join(path,\"business_data.csv\")    \\ndfb = pd.read_csv(filename, na_values=[\\'NA\\', \\'?\\'])\\n\\n\\nremoveLessThan20 = dfb[dfb[\\'review_count\\'] < 20].index\\ndfb.drop(removeLessThan20, inplace=True)\\ndfb[0:3]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\"\"\"path = \"/content/drive/MyDrive/yelp_dataset/\"\n",
        "    \n",
        "filename = os.path.join(path,\"business_data.csv\")    \n",
        "dfb = pd.read_csv(filename, na_values=['NA', '?'])\n",
        "\n",
        "\n",
        "removeLessThan20 = dfb[dfb['review_count'] < 20].index\n",
        "dfb.drop(removeLessThan20, inplace=True)\n",
        "dfb[0:3]\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"path = \"/content/drive/MyDrive/yelp_dataset/\"\n",
        "\n",
        "filename = os.path.join(path, \"reviews_merged.csv\")\n",
        "df_b = pd.read_csv(filename)\n",
        "\n",
        "df_b\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "VWRm6_DJQZ2Z",
        "outputId": "241bd8c3-4400-4dc5-87ce-206a390700d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'path = \"/content/drive/MyDrive/yelp_dataset/\"\\n\\nfilename = os.path.join(path, \"reviews_merged.csv\")\\ndf_b = pd.read_csv(filename)\\n\\ndf_b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"merged_df = pd.merge(df_b, dfb, on='business_id')\n",
        "merged_df[0:5]\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "kDp46-lRkdJs",
        "outputId": "ac6dd829-4baf-418b-83f9-157a86c1f986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"merged_df = pd.merge(df_b, dfb, on='business_id')\\nmerged_df[0:5]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"merged_df.to_csv(r'/content/drive/MyDrive/yelp_dataset/merged_business_and_review.csv', index = False)\"\"\""
      ],
      "metadata": {
        "id": "Mi_hp0nulIc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "dffecb7d-c72d-4b07-8049-234fee91e5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"merged_df.to_csv(r'/content/drive/MyDrive/yelp_dataset/merged_business_and_review.csv', index = False)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"merged_df[12345:12348]\"\"\""
      ],
      "metadata": {
        "id": "GXFbuKx_mlmM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "41ed7709-4429-4c11-e9c8-4c284188f45d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'merged_df[12345:12348]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"path = \"/content/drive/MyDrive/yelp_dataset/\"\n",
        "    \n",
        "filename = os.path.join(path,\"merged_business_and_review.csv\")    \n",
        "dfa = pd.read_csv(filename)\n",
        "\n",
        "dfa.drop(['business_id', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'is_open', 'hours', 'attributes', 'categories'], axis=1, inplace=True)\n",
        "dfa[0:3]\"\"\""
      ],
      "metadata": {
        "id": "f4GKxt3-nEem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d542ffe7-e812-484a-89fb-0ae02a5f661c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'path = \"/content/drive/MyDrive/yelp_dataset/\"\\n    \\nfilename = os.path.join(path,\"merged_business_and_review.csv\")    \\ndfa = pd.read_csv(filename)\\n\\ndfa.drop([\\'business_id\\', \\'address\\', \\'city\\', \\'state\\', \\'postal_code\\', \\'latitude\\', \\'longitude\\', \\'is_open\\', \\'hours\\', \\'attributes\\', \\'categories\\'], axis=1, inplace=True)\\ndfa[0:3]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"dfa.to_csv(r'/content/drive/MyDrive/yelp_dataset/transformed_data.csv', index = False)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "dx2wstbDSdNh",
        "outputId": "0779e030-1ac0-4197-b8d1-9b4264eb4f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"dfa.to_csv(r'/content/drive/MyDrive/yelp_dataset/transformed_data.csv', index = False)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/yelp_dataset/'\n",
        "filename_read = os.path.join(path, 'transformed_data.csv')\n",
        "df = pd.read_csv(filename_read, na_values=['NA', '?'])\n",
        "df.drop(['business_id', 'attributes', 'categories'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "eJOC9S8XrP7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_lite = df[:-51919]\n",
        "business_names = data_lite['name']\n",
        "data_lite.drop(['name'], axis=1, inplace=True)\n",
        "data_lite"
      ],
      "metadata": {
        "id": "qsiyJA3_vCLE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "4868b4a0-a963-4da2-a330-af65a7ea0568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            all_reviews  stars  review_count\n",
              "0     b\"Ate here for the 1st time on Saturday 08/07/...    4.5            24\n",
              "1     b'Took me for 40 bucks through grubhub, no cal...    3.0            27\n",
              "2     b'I loved this!!!! I was set up on a blind dat...    5.0            29\n",
              "3     b'What a great neighborhood place to wine it u...    4.5            23\n",
              "4     b\"This is my go to car wash establishment. Tod...    3.5            40\n",
              "...                                                 ...    ...           ...\n",
              "9995  b\"Try the pepperoni and bacon pizza, OMG!! I'v...    3.0            21\n",
              "9996  b'Love SK NAILS...and Kim does a fantastic job...    3.5            23\n",
              "9997  b\"Took my dog in after she scratched her eye o...    4.5            63\n",
              "9998  b'Previously had trouble recognizing high qual...    4.0           106\n",
              "9999  b\"Let me preface this by saying I am a die-har...    4.5           108\n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8af7bd10-8a0f-4521-8877-bb7d6fe5ecc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>all_reviews</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b\"Ate here for the 1st time on Saturday 08/07/...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'Took me for 40 bucks through grubhub, no cal...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'I loved this!!!! I was set up on a blind dat...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'What a great neighborhood place to wine it u...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b\"This is my go to car wash establishment. Tod...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>b\"Try the pepperoni and bacon pizza, OMG!! I'v...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>b'Love SK NAILS...and Kim does a fantastic job...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>b\"Took my dog in after she scratched her eye o...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>b'Previously had trouble recognizing high qual...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>b\"Let me preface this by saying I am a die-har...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8af7bd10-8a0f-4521-8877-bb7d6fe5ecc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8af7bd10-8a0f-4521-8877-bb7d6fe5ecc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8af7bd10-8a0f-4521-8877-bb7d6fe5ecc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = sk_text.TfidfVectorizer(max_features=2450, min_df=2, strip_accents='ascii')\n",
        "matrix = vectorizer.fit_transform(data_lite['all_reviews'])\n",
        "\n"
      ],
      "metadata": {
        "id": "bAvFp3OksdfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_data = matrix.toarray()\n",
        "#print(tfidf_data.shape)\n",
        "#print(vectorizer.get_feature_names())\n",
        "#print(len(vectorizer.get_feature_names()))\n",
        "#'x81', 'x82', 'x83', 'x8b', 'xad', 'xbbl', 'xbc', 'xe3', 'xe4', 'xe5', 'xe6', 'xe7', 'xe8', 'xe9'\n",
        "\n",
        "data_1 = tfidf_data\n",
        "df_1 = pd.DataFrame(data=data_1, columns=vectorizer.get_feature_names_out())\n",
        "df_1.drop(['x81', 'xe3'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "bepHtXF7-ctA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_lite2 = pd.merge(df_1, data_lite, left_index=True, right_index=True)\n",
        "data_lite2.drop('all_reviews', axis=1, inplace=True)\n",
        "data_lite2"
      ],
      "metadata": {
        "id": "LNtFlUDgqelX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "025eedfe-53c0-4d37-f933-f6617b3d2fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            00        10       100        11        12        13   14  \\\n",
              "0     0.000000  0.007720  0.000000  0.000000  0.000000  0.000000  0.0   \n",
              "1     0.007556  0.015220  0.000000  0.000000  0.000000  0.010139  0.0   \n",
              "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.009056  0.0   \n",
              "3     0.000000  0.013522  0.000000  0.000000  0.000000  0.000000  0.0   \n",
              "4     0.000000  0.009017  0.000000  0.004719  0.000000  0.000000  0.0   \n",
              "...        ...       ...       ...       ...       ...       ...  ...   \n",
              "9995  0.000000  0.005911  0.000000  0.000000  0.000000  0.000000  0.0   \n",
              "9996  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
              "9997  0.000000  0.000000  0.000000  0.000000  0.002748  0.003909  0.0   \n",
              "9998  0.001808  0.006068  0.003755  0.000953  0.003410  0.000000  0.0   \n",
              "9999  0.000000  0.006334  0.002450  0.000000  0.006675  0.003165  0.0   \n",
              "\n",
              "            15       16   17  ...      york       you     young      your  \\\n",
              "0     0.000000  0.00000  0.0  ...  0.000000  0.034072  0.011467  0.020651   \n",
              "1     0.017987  0.00000  0.0  ...  0.000000  0.076126  0.000000  0.013570   \n",
              "2     0.000000  0.00000  0.0  ...  0.000000  0.163996  0.000000  0.016162   \n",
              "3     0.000000  0.00000  0.0  ...  0.000000  0.089513  0.000000  0.030140   \n",
              "4     0.017761  0.01211  0.0  ...  0.000000  0.079589  0.000000  0.050918   \n",
              "...        ...      ...  ...  ...       ...       ...       ...       ...   \n",
              "9995  0.006986  0.00000  0.0  ...  0.000000  0.020870  0.008779  0.026352   \n",
              "9996  0.000000  0.00000  0.0  ...  0.000000  0.092312  0.000000  0.031083   \n",
              "9997  0.004624  0.00000  0.0  ...  0.000000  0.069063  0.002905  0.034882   \n",
              "9998  0.003586  0.00000  0.0  ...  0.001482  0.102834  0.000000  0.016772   \n",
              "9999  0.001872  0.00000  0.0  ...  0.000000  0.117414  0.007056  0.025416   \n",
              "\n",
              "      yourself       yum     yummy      zero  stars_y  review_count  \n",
              "0     0.000000  0.014885  0.000000  0.000000      4.5            24  \n",
              "1     0.007145  0.000000  0.008107  0.000000      3.0            27  \n",
              "2     0.006382  0.000000  0.000000  0.000000      5.0            29  \n",
              "3     0.000000  0.000000  0.000000  0.000000      4.5            23  \n",
              "4     0.000000  0.000000  0.000000  0.021262      3.5            40  \n",
              "...        ...       ...       ...       ...      ...           ...  \n",
              "9995  0.000000  0.034189  0.000000  0.000000      3.0            21  \n",
              "9996  0.000000  0.000000  0.000000  0.000000      3.5            23  \n",
              "9997  0.002755  0.000000  0.000000  0.000000      4.5            63  \n",
              "9998  0.001709  0.000000  0.002909  0.000000      4.0           106  \n",
              "9999  0.000000  0.006106  0.010123  0.000000      4.5           108  \n",
              "\n",
              "[10000 rows x 2450 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-223def9a-7d11-4d7d-b7ae-a616bfc8026e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>...</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>zero</th>\n",
              "      <th>stars_y</th>\n",
              "      <th>review_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034072</td>\n",
              "      <td>0.011467</td>\n",
              "      <td>0.020651</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.007556</td>\n",
              "      <td>0.015220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010139</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017987</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076126</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013570</td>\n",
              "      <td>0.007145</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.163996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016162</td>\n",
              "      <td>0.006382</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.089513</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017761</td>\n",
              "      <td>0.01211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079589</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021262</td>\n",
              "      <td>3.5</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005911</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006986</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020870</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>0.026352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.092312</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.5</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002748</td>\n",
              "      <td>0.003909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004624</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.069063</td>\n",
              "      <td>0.002905</td>\n",
              "      <td>0.034882</td>\n",
              "      <td>0.002755</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.001808</td>\n",
              "      <td>0.006068</td>\n",
              "      <td>0.003755</td>\n",
              "      <td>0.000953</td>\n",
              "      <td>0.003410</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003586</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001482</td>\n",
              "      <td>0.102834</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016772</td>\n",
              "      <td>0.001709</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006334</td>\n",
              "      <td>0.002450</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006675</td>\n",
              "      <td>0.003165</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117414</td>\n",
              "      <td>0.007056</td>\n",
              "      <td>0.025416</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006106</td>\n",
              "      <td>0.010123</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2450 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-223def9a-7d11-4d7d-b7ae-a616bfc8026e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-223def9a-7d11-4d7d-b7ae-a616bfc8026e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-223def9a-7d11-4d7d-b7ae-a616bfc8026e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tfidf_data = tfidf_data.to_numpy()\n",
        "x, y = to_xy(data_lite2, \"stars_y\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42) \n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "ZO340SKz5w1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c21de3b-d67b-4cbb-9430-2ab8cad03d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 2449)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Low neuron count and one hidden layer: RMSE score between 0.47 and 0.38\n",
        "\n",
        "\"\"\"checkpointer_m1 = ModelCheckpoint(filepath=\"/content/drive/MyDrive/yelp_dataset/dnn/best_weights_prev_models.hdf5\", verbose=0, save_best_only=True) # save best model\n",
        "\n",
        "for i in range(5):\n",
        "    print(i)\n",
        "\n",
        "    # Build network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(22, input_dim=x.shape[1], activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer_m1],verbose=2,epochs=100)\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/yelp_dataset/dnn/best_weights.hdf5')\"\"\""
      ],
      "metadata": {
        "id": "lyAsHSz5UqOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# High neuron count and three hidden layers, SGD optimizer: RMSE score between 0.58 and 0.45\n",
        "\n",
        "\"\"\"checkpointer_m2 = ModelCheckpoint(filepath=\"/content/drive/MyDrive/yelp_dataset/dnn/best_weights_prev_models.hdf5\", verbose=0, save_best_only=True) # save best model\n",
        "\n",
        "for i in range(5):\n",
        "    print(i)\n",
        "\n",
        "    # Build network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(550, input_dim=x.shape[1], activation='sigmoid'))\n",
        "    model.add(Dense(90, activation='relu'))\n",
        "    model.add(Dense(25, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='SGD')\n",
        "\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer_m2],verbose=2,epochs=100)\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/yelp_dataset/dnn/best_weights.hdf5')\"\"\""
      ],
      "metadata": {
        "id": "2NgsSg14UqyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Low neuron count and two hidden layers, SGD optimizer: RMSE score around 0.84\n",
        "\n",
        "checkpointer_m3 = ModelCheckpoint(filepath=\"/content/drive/MyDrive/yelp_dataset/dnn/best_weights_prev_models.hdf5\", verbose=0, save_best_only=True) # save best model\n",
        "\n",
        "for i in range(2):\n",
        "    print(i)\n",
        "\n",
        "    # Build network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(30, input_dim=x.shape[1], activation='relu'))\n",
        "    model.add(Dense(15, activation='relu'))\n",
        "    model.add(Dense(10, activation='tanh'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='SGD')\n",
        "\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=15, verbose=1, mode='auto')\n",
        "\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer_m3],verbose=2,epochs=100)\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/yelp_dataset/dnn/best_weights.hdf5')\n",
        "\n"
      ],
      "metadata": {
        "id": "paJnbqWrGgbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer = ModelCheckpoint(filepath=\"/content/drive/MyDrive/yelp_dataset/dnn/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
        "\n",
        "for i in range(5):\n",
        "    print(i)\n",
        "\n",
        "    # Build network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=x.shape[1], activation='relu'))\n",
        "    model.add(Dense(25, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(5, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=7, verbose=1, mode='auto')\n",
        "\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=100)\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/yelp_dataset/dnn/best_weights.hdf5')\n",
        "\n"
      ],
      "metadata": {
        "id": "vsMQCfj366Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc02d454-6cf1-4528-b52f-dc0bcf5b8ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch 1/100\n",
            "250/250 - 1s - loss: 4.3824 - val_loss: 0.7984 - 1s/epoch - 6ms/step\n",
            "Epoch 2/100\n",
            "250/250 - 1s - loss: 0.6261 - val_loss: 0.4552 - 778ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "250/250 - 1s - loss: 0.3235 - val_loss: 0.2114 - 725ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "250/250 - 1s - loss: 0.1735 - val_loss: 0.1741 - 736ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "250/250 - 1s - loss: 0.1419 - val_loss: 0.1453 - 816ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "250/250 - 1s - loss: 0.1262 - val_loss: 0.1436 - 774ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "250/250 - 1s - loss: 0.1017 - val_loss: 0.1129 - 772ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "250/250 - 1s - loss: 0.2565 - val_loss: 0.2902 - 693ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "250/250 - 1s - loss: 0.1143 - val_loss: 0.1242 - 637ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "250/250 - 1s - loss: 0.0905 - val_loss: 0.1061 - 722ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "250/250 - 1s - loss: 0.0908 - val_loss: 0.1180 - 748ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "250/250 - 1s - loss: 0.0926 - val_loss: 0.1003 - 1s/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "250/250 - 2s - loss: 0.0885 - val_loss: 0.1870 - 2s/epoch - 9ms/step\n",
            "Epoch 14/100\n",
            "250/250 - 1s - loss: 0.0787 - val_loss: 0.0902 - 1s/epoch - 6ms/step\n",
            "Epoch 15/100\n",
            "250/250 - 1s - loss: 0.0837 - val_loss: 0.0916 - 1s/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "250/250 - 1s - loss: 0.1349 - val_loss: 0.1002 - 1s/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "250/250 - 3s - loss: 0.0803 - val_loss: 0.0921 - 3s/epoch - 10ms/step\n",
            "Epoch 18/100\n",
            "250/250 - 2s - loss: 0.0728 - val_loss: 0.0973 - 2s/epoch - 10ms/step\n",
            "Epoch 19/100\n",
            "250/250 - 2s - loss: 0.0738 - val_loss: 0.0942 - 2s/epoch - 9ms/step\n",
            "Epoch 20/100\n",
            "250/250 - 3s - loss: 0.0772 - val_loss: 0.0945 - 3s/epoch - 10ms/step\n",
            "Epoch 21/100\n",
            "250/250 - 3s - loss: 0.0912 - val_loss: 0.0889 - 3s/epoch - 11ms/step\n",
            "Epoch 22/100\n",
            "250/250 - 2s - loss: 0.0815 - val_loss: 0.0970 - 2s/epoch - 10ms/step\n",
            "Epoch 23/100\n",
            "250/250 - 3s - loss: 0.0737 - val_loss: 0.0850 - 3s/epoch - 13ms/step\n",
            "Epoch 24/100\n",
            "250/250 - 2s - loss: 0.0694 - val_loss: 0.0880 - 2s/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "250/250 - 1s - loss: 0.0760 - val_loss: 0.0905 - 1s/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "250/250 - 3s - loss: 0.0653 - val_loss: 0.1369 - 3s/epoch - 10ms/step\n",
            "Epoch 27/100\n",
            "250/250 - 3s - loss: 0.0696 - val_loss: 0.0823 - 3s/epoch - 11ms/step\n",
            "Epoch 28/100\n",
            "250/250 - 3s - loss: 0.0653 - val_loss: 0.0820 - 3s/epoch - 11ms/step\n",
            "Epoch 29/100\n",
            "250/250 - 3s - loss: 0.0761 - val_loss: 0.1018 - 3s/epoch - 10ms/step\n",
            "Epoch 30/100\n",
            "250/250 - 2s - loss: 0.0676 - val_loss: 0.0822 - 2s/epoch - 10ms/step\n",
            "Epoch 31/100\n",
            "250/250 - 3s - loss: 0.0829 - val_loss: 0.0919 - 3s/epoch - 10ms/step\n",
            "Epoch 32/100\n",
            "250/250 - 1s - loss: 0.0616 - val_loss: 0.0847 - 1s/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "250/250 - 1s - loss: 0.0653 - val_loss: 0.0837 - 1s/epoch - 6ms/step\n",
            "Epoch 34/100\n",
            "250/250 - 3s - loss: 0.0616 - val_loss: 0.0816 - 3s/epoch - 12ms/step\n",
            "Epoch 35/100\n",
            "250/250 - 3s - loss: 0.0892 - val_loss: 0.1203 - 3s/epoch - 11ms/step\n",
            "Epoch 36/100\n",
            "250/250 - 2s - loss: 0.0606 - val_loss: 0.0854 - 2s/epoch - 10ms/step\n",
            "Epoch 37/100\n",
            "250/250 - 3s - loss: 0.0548 - val_loss: 0.0809 - 3s/epoch - 11ms/step\n",
            "Epoch 38/100\n",
            "250/250 - 1s - loss: 0.0598 - val_loss: 0.0790 - 1s/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "250/250 - 1s - loss: 0.0566 - val_loss: 0.0796 - 1s/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "250/250 - 3s - loss: 0.0562 - val_loss: 0.0963 - 3s/epoch - 10ms/step\n",
            "Epoch 41/100\n",
            "250/250 - 1s - loss: 0.0637 - val_loss: 0.0828 - 1s/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "250/250 - 1s - loss: 0.0533 - val_loss: 0.0808 - 1s/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "250/250 - 1s - loss: 0.0518 - val_loss: 0.0929 - 1s/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "250/250 - 2s - loss: 0.0528 - val_loss: 0.0841 - 2s/epoch - 10ms/step\n",
            "Epoch 45/100\n",
            "250/250 - 2s - loss: 0.0579 - val_loss: 0.0839 - 2s/epoch - 9ms/step\n",
            "Epoch 45: early stopping\n",
            "1\n",
            "Epoch 1/100\n",
            "250/250 - 3s - loss: 6.8750 - val_loss: 1.4956 - 3s/epoch - 13ms/step\n",
            "Epoch 2/100\n",
            "250/250 - 3s - loss: 0.8342 - val_loss: 0.7108 - 3s/epoch - 11ms/step\n",
            "Epoch 3/100\n",
            "250/250 - 2s - loss: 0.5720 - val_loss: 0.4454 - 2s/epoch - 10ms/step\n",
            "Epoch 4/100\n",
            "250/250 - 1s - loss: 0.3338 - val_loss: 0.2577 - 1s/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "250/250 - 3s - loss: 0.2081 - val_loss: 0.3116 - 3s/epoch - 11ms/step\n",
            "Epoch 6/100\n",
            "250/250 - 1s - loss: 0.1488 - val_loss: 0.1777 - 1s/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "250/250 - 2s - loss: 0.1354 - val_loss: 0.1352 - 2s/epoch - 10ms/step\n",
            "Epoch 8/100\n",
            "250/250 - 2s - loss: 0.1419 - val_loss: 0.1419 - 2s/epoch - 10ms/step\n",
            "Epoch 9/100\n",
            "250/250 - 3s - loss: 0.1087 - val_loss: 0.1269 - 3s/epoch - 10ms/step\n",
            "Epoch 10/100\n",
            "250/250 - 3s - loss: 0.1245 - val_loss: 1.3620 - 3s/epoch - 10ms/step\n",
            "Epoch 11/100\n",
            "250/250 - 1s - loss: 0.1361 - val_loss: 0.1114 - 1s/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "250/250 - 3s - loss: 0.0942 - val_loss: 0.1133 - 3s/epoch - 10ms/step\n",
            "Epoch 13/100\n",
            "250/250 - 2s - loss: 0.0881 - val_loss: 0.1050 - 2s/epoch - 10ms/step\n",
            "Epoch 14/100\n",
            "250/250 - 3s - loss: 0.1016 - val_loss: 0.1602 - 3s/epoch - 10ms/step\n",
            "Epoch 15/100\n",
            "250/250 - 1s - loss: 0.1181 - val_loss: 0.1102 - 1s/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "250/250 - 3s - loss: 0.0981 - val_loss: 0.1423 - 3s/epoch - 11ms/step\n",
            "Epoch 17/100\n",
            "250/250 - 2s - loss: 0.1030 - val_loss: 0.1158 - 2s/epoch - 10ms/step\n",
            "Epoch 18/100\n",
            "250/250 - 3s - loss: 0.1867 - val_loss: 0.1240 - 3s/epoch - 10ms/step\n",
            "Epoch 19/100\n",
            "250/250 - 3s - loss: 0.0821 - val_loss: 0.1051 - 3s/epoch - 10ms/step\n",
            "Epoch 20/100\n",
            "250/250 - 3s - loss: 0.0780 - val_loss: 0.0955 - 3s/epoch - 10ms/step\n",
            "Epoch 21/100\n",
            "250/250 - 3s - loss: 0.0829 - val_loss: 0.1084 - 3s/epoch - 10ms/step\n",
            "Epoch 22/100\n",
            "250/250 - 1s - loss: 0.0910 - val_loss: 0.1221 - 1s/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "250/250 - 1s - loss: 0.0750 - val_loss: 0.0952 - 1s/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "250/250 - 3s - loss: 0.0877 - val_loss: 0.2844 - 3s/epoch - 10ms/step\n",
            "Epoch 25/100\n",
            "250/250 - 3s - loss: 0.0820 - val_loss: 0.0922 - 3s/epoch - 10ms/step\n",
            "Epoch 26/100\n",
            "250/250 - 2s - loss: 0.0809 - val_loss: 0.0981 - 2s/epoch - 10ms/step\n",
            "Epoch 27/100\n",
            "250/250 - 2s - loss: 0.0885 - val_loss: 0.1108 - 2s/epoch - 10ms/step\n",
            "Epoch 28/100\n",
            "250/250 - 2s - loss: 0.0759 - val_loss: 0.0988 - 2s/epoch - 10ms/step\n",
            "Epoch 29/100\n",
            "250/250 - 2s - loss: 0.0689 - val_loss: 0.0977 - 2s/epoch - 10ms/step\n",
            "Epoch 30/100\n",
            "250/250 - 3s - loss: 0.1075 - val_loss: 0.1079 - 3s/epoch - 10ms/step\n",
            "Epoch 31/100\n",
            "250/250 - 2s - loss: 0.0694 - val_loss: 0.1011 - 2s/epoch - 9ms/step\n",
            "Epoch 32/100\n",
            "250/250 - 3s - loss: 0.0698 - val_loss: 0.1452 - 3s/epoch - 10ms/step\n",
            "Epoch 32: early stopping\n",
            "2\n",
            "Epoch 1/100\n",
            "250/250 - 3s - loss: 6.2094 - val_loss: 0.9299 - 3s/epoch - 13ms/step\n",
            "Epoch 2/100\n",
            "250/250 - 2s - loss: 0.7527 - val_loss: 0.5567 - 2s/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "250/250 - 1s - loss: 0.4182 - val_loss: 0.3071 - 1s/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "250/250 - 1s - loss: 0.2474 - val_loss: 0.1681 - 1s/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "250/250 - 2s - loss: 0.1752 - val_loss: 0.1881 - 2s/epoch - 9ms/step\n",
            "Epoch 6/100\n",
            "250/250 - 2s - loss: 0.1890 - val_loss: 0.1227 - 2s/epoch - 9ms/step\n",
            "Epoch 7/100\n",
            "250/250 - 2s - loss: 0.1276 - val_loss: 0.1336 - 2s/epoch - 10ms/step\n",
            "Epoch 8/100\n",
            "250/250 - 2s - loss: 0.1179 - val_loss: 0.1198 - 2s/epoch - 10ms/step\n",
            "Epoch 9/100\n",
            "250/250 - 2s - loss: 0.1055 - val_loss: 0.1046 - 2s/epoch - 10ms/step\n",
            "Epoch 10/100\n",
            "250/250 - 2s - loss: 0.0988 - val_loss: 0.2174 - 2s/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "250/250 - 3s - loss: 0.1894 - val_loss: 0.1007 - 3s/epoch - 10ms/step\n",
            "Epoch 12/100\n",
            "250/250 - 2s - loss: 0.1013 - val_loss: 0.0978 - 2s/epoch - 10ms/step\n",
            "Epoch 13/100\n",
            "250/250 - 2s - loss: 0.1002 - val_loss: 0.0993 - 2s/epoch - 10ms/step\n",
            "Epoch 14/100\n",
            "250/250 - 3s - loss: 0.1436 - val_loss: 0.1012 - 3s/epoch - 10ms/step\n",
            "Epoch 15/100\n",
            "250/250 - 2s - loss: 0.0944 - val_loss: 0.0982 - 2s/epoch - 10ms/step\n",
            "Epoch 16/100\n",
            "250/250 - 2s - loss: 0.0821 - val_loss: 0.0934 - 2s/epoch - 10ms/step\n",
            "Epoch 17/100\n",
            "250/250 - 2s - loss: 0.1091 - val_loss: 0.5092 - 2s/epoch - 10ms/step\n",
            "Epoch 18/100\n",
            "250/250 - 2s - loss: 0.1083 - val_loss: 0.0990 - 2s/epoch - 10ms/step\n",
            "Epoch 19/100\n",
            "250/250 - 2s - loss: 0.0825 - val_loss: 0.1166 - 2s/epoch - 10ms/step\n",
            "Epoch 20/100\n",
            "250/250 - 2s - loss: 0.1429 - val_loss: 0.2054 - 2s/epoch - 10ms/step\n",
            "Epoch 21/100\n",
            "250/250 - 3s - loss: 0.0939 - val_loss: 0.0972 - 3s/epoch - 10ms/step\n",
            "Epoch 22/100\n",
            "250/250 - 3s - loss: 0.0834 - val_loss: 0.1082 - 3s/epoch - 10ms/step\n",
            "Epoch 23/100\n",
            "250/250 - 2s - loss: 0.1141 - val_loss: 0.0969 - 2s/epoch - 10ms/step\n",
            "Epoch 23: early stopping\n",
            "3\n",
            "Epoch 1/100\n",
            "250/250 - 3s - loss: 5.5283 - val_loss: 0.8643 - 3s/epoch - 13ms/step\n",
            "Epoch 2/100\n",
            "250/250 - 2s - loss: 0.7330 - val_loss: 0.5673 - 2s/epoch - 10ms/step\n",
            "Epoch 3/100\n",
            "250/250 - 2s - loss: 0.4200 - val_loss: 0.3682 - 2s/epoch - 8ms/step\n",
            "Epoch 4/100\n",
            "250/250 - 3s - loss: 0.2205 - val_loss: 0.1889 - 3s/epoch - 10ms/step\n",
            "Epoch 5/100\n",
            "250/250 - 3s - loss: 0.1676 - val_loss: 0.1343 - 3s/epoch - 10ms/step\n",
            "Epoch 6/100\n",
            "250/250 - 2s - loss: 0.1283 - val_loss: 0.1172 - 2s/epoch - 10ms/step\n",
            "Epoch 7/100\n",
            "250/250 - 3s - loss: 0.1550 - val_loss: 0.1578 - 3s/epoch - 10ms/step\n",
            "Epoch 8/100\n",
            "250/250 - 3s - loss: 0.1313 - val_loss: 0.1231 - 3s/epoch - 10ms/step\n",
            "Epoch 9/100\n",
            "250/250 - 2s - loss: 0.1123 - val_loss: 0.1169 - 2s/epoch - 7ms/step\n",
            "Epoch 10/100\n",
            "250/250 - 3s - loss: 0.0996 - val_loss: 0.1200 - 3s/epoch - 10ms/step\n",
            "Epoch 11/100\n",
            "250/250 - 3s - loss: 0.0970 - val_loss: 0.1076 - 3s/epoch - 10ms/step\n",
            "Epoch 12/100\n",
            "250/250 - 3s - loss: 0.0945 - val_loss: 0.0988 - 3s/epoch - 10ms/step\n",
            "Epoch 13/100\n",
            "250/250 - 1s - loss: 0.0867 - val_loss: 0.0962 - 1s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "250/250 - 1s - loss: 0.1065 - val_loss: 0.1026 - 1s/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "250/250 - 1s - loss: 0.0882 - val_loss: 0.0963 - 1s/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "250/250 - 2s - loss: 0.0992 - val_loss: 0.0927 - 2s/epoch - 10ms/step\n",
            "Epoch 17/100\n",
            "250/250 - 2s - loss: 0.0905 - val_loss: 0.0980 - 2s/epoch - 8ms/step\n",
            "Epoch 18/100\n",
            "250/250 - 2s - loss: 0.0817 - val_loss: 0.1428 - 2s/epoch - 10ms/step\n",
            "Epoch 19/100\n",
            "250/250 - 2s - loss: 0.0949 - val_loss: 0.1085 - 2s/epoch - 10ms/step\n",
            "Epoch 20/100\n",
            "250/250 - 3s - loss: 0.0791 - val_loss: 0.1053 - 3s/epoch - 10ms/step\n",
            "Epoch 21/100\n",
            "250/250 - 3s - loss: 0.0940 - val_loss: 0.3002 - 3s/epoch - 10ms/step\n",
            "Epoch 22/100\n",
            "250/250 - 3s - loss: 0.0837 - val_loss: 0.0898 - 3s/epoch - 10ms/step\n",
            "Epoch 23/100\n",
            "250/250 - 1s - loss: 0.0725 - val_loss: 0.0883 - 1s/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "250/250 - 3s - loss: 0.0729 - val_loss: 0.1039 - 3s/epoch - 10ms/step\n",
            "Epoch 25/100\n",
            "250/250 - 3s - loss: 0.0728 - val_loss: 0.1011 - 3s/epoch - 10ms/step\n",
            "Epoch 26/100\n",
            "250/250 - 1s - loss: 0.0931 - val_loss: 0.0914 - 1s/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "250/250 - 2s - loss: 0.0859 - val_loss: 0.0940 - 2s/epoch - 10ms/step\n",
            "Epoch 28/100\n",
            "250/250 - 3s - loss: 0.0785 - val_loss: 0.0951 - 3s/epoch - 10ms/step\n",
            "Epoch 29/100\n",
            "250/250 - 3s - loss: 0.0686 - val_loss: 0.1489 - 3s/epoch - 11ms/step\n",
            "Epoch 30/100\n",
            "250/250 - 3s - loss: 0.0690 - val_loss: 0.1066 - 3s/epoch - 11ms/step\n",
            "Epoch 30: early stopping\n",
            "4\n",
            "Epoch 1/100\n",
            "250/250 - 3s - loss: 12.9040 - val_loss: 12.1162 - 3s/epoch - 12ms/step\n",
            "Epoch 2/100\n",
            "250/250 - 1s - loss: 11.2623 - val_loss: 10.5657 - 1s/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "250/250 - 2s - loss: 9.7990 - val_loss: 9.1742 - 2s/epoch - 10ms/step\n",
            "Epoch 4/100\n",
            "250/250 - 2s - loss: 8.4886 - val_loss: 7.9299 - 2s/epoch - 9ms/step\n",
            "Epoch 5/100\n",
            "250/250 - 1s - loss: 7.3193 - val_loss: 6.8216 - 1s/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "250/250 - 1s - loss: 6.2808 - val_loss: 5.8399 - 1s/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "250/250 - 1s - loss: 5.3621 - val_loss: 4.9733 - 1s/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "250/250 - 1s - loss: 4.5552 - val_loss: 4.2132 - 698ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "250/250 - 1s - loss: 3.8517 - val_loss: 3.5549 - 738ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "250/250 - 1s - loss: 3.2431 - val_loss: 2.9857 - 1s/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "250/250 - 1s - loss: 2.7219 - val_loss: 2.5011 - 1s/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "250/250 - 1s - loss: 2.2817 - val_loss: 2.0941 - 1s/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "250/250 - 1s - loss: 1.9147 - val_loss: 1.7571 - 1s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "250/250 - 2s - loss: 1.6136 - val_loss: 1.4830 - 2s/epoch - 10ms/step\n",
            "Epoch 15/100\n",
            "250/250 - 1s - loss: 1.3719 - val_loss: 1.2647 - 1s/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "250/250 - 1s - loss: 1.1819 - val_loss: 1.0951 - 1s/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "250/250 - 3s - loss: 1.0369 - val_loss: 0.9673 - 3s/epoch - 10ms/step\n",
            "Epoch 18/100\n",
            "250/250 - 2s - loss: 0.9298 - val_loss: 0.8742 - 2s/epoch - 7ms/step\n",
            "Epoch 19/100\n",
            "250/250 - 1s - loss: 0.8537 - val_loss: 0.8087 - 1s/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "250/250 - 2s - loss: 0.8021 - val_loss: 0.7652 - 2s/epoch - 10ms/step\n",
            "Epoch 21/100\n",
            "250/250 - 3s - loss: 0.7692 - val_loss: 0.7377 - 3s/epoch - 10ms/step\n",
            "Epoch 22/100\n",
            "250/250 - 2s - loss: 0.7493 - val_loss: 0.7215 - 2s/epoch - 10ms/step\n",
            "Epoch 23/100\n",
            "250/250 - 2s - loss: 0.7380 - val_loss: 0.7124 - 2s/epoch - 10ms/step\n",
            "Epoch 24/100\n",
            "250/250 - 2s - loss: 0.7320 - val_loss: 0.7075 - 2s/epoch - 10ms/step\n",
            "Epoch 25/100\n",
            "250/250 - 3s - loss: 0.7293 - val_loss: 0.7051 - 3s/epoch - 10ms/step\n",
            "Epoch 26/100\n",
            "250/250 - 2s - loss: 0.7283 - val_loss: 0.7041 - 2s/epoch - 10ms/step\n",
            "Epoch 27/100\n",
            "250/250 - 3s - loss: 0.7278 - val_loss: 0.7037 - 3s/epoch - 10ms/step\n",
            "Epoch 28/100\n",
            "250/250 - 3s - loss: 0.7277 - val_loss: 0.7034 - 3s/epoch - 10ms/step\n",
            "Epoch 29/100\n",
            "250/250 - 3s - loss: 0.7277 - val_loss: 0.7033 - 3s/epoch - 10ms/step\n",
            "Epoch 30/100\n",
            "250/250 - 3s - loss: 0.7277 - val_loss: 0.7033 - 3s/epoch - 10ms/step\n",
            "Epoch 31/100\n",
            "250/250 - 3s - loss: 0.7277 - val_loss: 0.7032 - 3s/epoch - 10ms/step\n",
            "Epoch 32/100\n",
            "250/250 - 3s - loss: 0.7277 - val_loss: 0.7033 - 3s/epoch - 10ms/step\n",
            "Epoch 33/100\n",
            "250/250 - 2s - loss: 0.7276 - val_loss: 0.7033 - 2s/epoch - 10ms/step\n",
            "Epoch 34/100\n",
            "250/250 - 2s - loss: 0.7276 - val_loss: 0.7033 - 2s/epoch - 10ms/step\n",
            "Epoch 35/100\n",
            "250/250 - 2s - loss: 0.7276 - val_loss: 0.7033 - 2s/epoch - 10ms/step\n",
            "Epoch 36/100\n",
            "250/250 - 2s - loss: 0.7277 - val_loss: 0.7032 - 2s/epoch - 10ms/step\n",
            "Epoch 37/100\n",
            "250/250 - 3s - loss: 0.7277 - val_loss: 0.7032 - 3s/epoch - 10ms/step\n",
            "Epoch 38/100\n",
            "250/250 - 1s - loss: 0.7277 - val_loss: 0.7034 - 1s/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "250/250 - 2s - loss: 0.7278 - val_loss: 0.7034 - 2s/epoch - 10ms/step\n",
            "Epoch 40/100\n",
            "250/250 - 3s - loss: 0.7277 - val_loss: 0.7034 - 3s/epoch - 10ms/step\n",
            "Epoch 41/100\n",
            "250/250 - 1s - loss: 0.7276 - val_loss: 0.7033 - 1s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "250/250 - 2s - loss: 0.7277 - val_loss: 0.7033 - 2s/epoch - 10ms/step\n",
            "Epoch 43/100\n",
            "250/250 - 2s - loss: 0.7277 - val_loss: 0.7033 - 2s/epoch - 10ms/step\n",
            "Epoch 43: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "print(\"Final score (RMSE): {}\".format(score))\n",
        "chart_regression(pred.flatten(), y_test, sort=True)"
      ],
      "metadata": {
        "id": "SbjbfGg9Acrq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "83a2f004-952e-4a74-ef68-097f63affb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final score (RMSE): 0.8407665491104126\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b1, b2, b3, b4, b5 = random.sample(range(0, 1999), 5)\n",
        "print(\"{}. Business name: {} || Actual stars: {} || Predicted stars: {}\".format(1,business_names[b1],y_test[b1],pred[b1]))\n",
        "print(\"{}. Business name: {} || Actual stars {} || Predicted stars: {}\".format(2,business_names[b2],y_test[b2],pred[b2]))\n",
        "print(\"{}. Business name: {} || Actual stars: {} || Predicted stars: {}\".format(3,business_names[b3],y_test[b3],pred[b3]))\n",
        "print(\"{}. Business name: {} || Actual stars: {} || Predicted stars: {}\".format(4,business_names[b4],y_test[b4],pred[b4]))\n",
        "print(\"{}. Business name: {} || Actual stars: {} || Predicted stars: {}\".format(5,business_names[b5],y_test[b5],pred[b5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viMRy_JZPFIl",
        "outputId": "5a88a706-a7f7-419c-8e2e-0fb4773b44ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Business name: Gandolfos New York Deli || Actual stars: 3.5 || Predicted stars: [3.557754]\n",
            "2. Business name: Studio Goddess || Actual stars 3.0 || Predicted stars: [2.8373337]\n",
            "3. Business name: Mister Car Wash || Actual stars: 2.5 || Predicted stars: [2.7861786]\n",
            "4. Business name: Renaud's Patisserie & Bistro || Actual stars: 3.5 || Predicted stars: [3.3707643]\n",
            "5. Business name: Pathmark || Actual stars: 2.5 || Predicted stars: [2.5683112]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}